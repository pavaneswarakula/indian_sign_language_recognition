{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "432221ff",
        "outputId": "46af6d8b-9f15-4291-84a7-d09c70cca06e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.5.0\n",
            "  Downloading tensorflow-2.5.0-cp39-cp39-manylinux2010_x86_64.whl (454.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.4/454.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-gpu==2.5.0\n",
            "  Downloading tensorflow_gpu-2.5.0-cp39-cp39-manylinux2010_x86_64.whl (454.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.4/454.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.9/dist-packages (4.7.0.72)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (3.7.1)\n",
            "Collecting keras-preprocessing~=1.1.2\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting termcolor~=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-nightly~=2.5.0.dev\n",
            "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio~=1.34.0\n",
            "  Downloading grpcio-1.34.1-cp39-cp39-manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (3.20.3)\n",
            "Collecting h5py~=3.1.0\n",
            "  Downloading h5py-3.1.0-cp39-cp39-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp39-cp39-manylinux2010_x86_64.whl (14.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
            "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.4/462.4 KB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (0.4.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (0.40.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (3.3.0)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting six~=1.15.0\n",
            "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (2.12.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (0.2.0)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (1.6.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (5.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (0.11.0)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.7.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading matplotlib-3.6.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (4.39.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\n",
            "Collecting tensorboard~=2.5\n",
            "  Downloading tensorboard-2.12.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m121.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m110.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.17.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.2.3)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m121.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (67.6.1)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.27.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (6.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.5->tensorflow==2.5.0) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (3.2.2)\n",
            "Building wheels for collected packages: sklearn, termcolor, wrapt\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2955 sha256=94024f5589b5af9fdedcd90abf9847c1a0f1734c5880e1ce0066ac2d03f6082d\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/e0/3d/9d0c2020c44a519b9f02ab4fa6d2a4a996c98d79ab2f569fa1\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4845 sha256=03cd094351db8f6b73d2d0d0da04b49dea1e5a50d030dc55ce88a804a3098cd3\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/0d/90/0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp39-cp39-linux_x86_64.whl size=75964 sha256=48c80e68933d980ceffa7c8edf0c3d5e124ae8a5f66c3b535622870425c5ef15\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/23/68/efe259aaca055e93b08e74fbe512819c69a2155c11ba3c0f10\n",
            "Successfully built sklearn termcolor wrapt\n",
            "Installing collected packages: wrapt, typing-extensions, termcolor, tensorflow-estimator, sklearn, keras-nightly, flatbuffers, tensorboard-data-server, six, numpy, keras-preprocessing, h5py, grpcio, absl-py, matplotlib, google-auth-oauthlib, tensorboard, tensorflow-gpu, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.2.0\n",
            "    Uninstalling termcolor-2.2.0:\n",
            "      Successfully uninstalled termcolor-2.2.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.3.3\n",
            "    Uninstalling flatbuffers-23.3.3:\n",
            "      Successfully uninstalled flatbuffers-23.3.3\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.0\n",
            "    Uninstalling tensorboard-data-server-0.7.0:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.0\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.8.0\n",
            "    Uninstalling h5py-3.8.0:\n",
            "      Successfully uninstalled h5py-3.8.0\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.53.0\n",
            "    Uninstalling grpcio-1.53.0:\n",
            "      Successfully uninstalled grpcio-1.53.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.1\n",
            "    Uninstalling tensorboard-2.12.1:\n",
            "      Successfully uninstalled tensorboard-2.12.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 2022.12.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "xarray-einstats 0.5.1 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "pydantic 1.10.7 requires typing-extensions>=4.2.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "optax 0.1.4 requires typing-extensions>=3.10.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "ml-dtypes 0.0.4 requires numpy>1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "librosa 0.10.0.post2 requires numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3, but you have numpy 1.19.5 which is incompatible.\n",
            "librosa 0.10.0.post2 requires typing-extensions>=4.1.1, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "jaxlib 0.4.7+cuda11.cudnn86 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "jax 0.4.7 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "grpcio-status 1.48.2 requires grpcio>=1.48.2, but you have grpcio 1.34.1 which is incompatible.\n",
            "google-cloud-bigquery 3.4.2 requires grpcio<2.0dev,>=1.47.0, but you have grpcio 1.34.1 which is incompatible.\n",
            "flax 0.6.8 requires typing-extensions>=4.1.1, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "cmdstanpy 1.1.0 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "chex 0.1.7 requires typing-extensions>=4.2.0; python_version < \"3.11\", but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "bokeh 2.4.3 requires typing-extensions>=3.10.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "astropy 5.2.2 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "arviz 0.15.1 requires numpy>=1.20.0, but you have numpy 1.19.5 which is incompatible.\n",
            "arviz 0.15.1 requires typing-extensions>=4.1.0, but you have typing-extensions 3.7.4.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed absl-py-0.15.0 flatbuffers-1.12 google-auth-oauthlib-0.4.6 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 matplotlib-3.6.3 numpy-1.19.5 six-1.15.0 sklearn-0.0.post1 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorflow-2.5.0 tensorflow-estimator-2.5.0 tensorflow-gpu-2.5.0 termcolor-1.1.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.5.0 tensorflow-gpu==2.5.0 opencv-python  sklearn matplotlib"
      ],
      "id": "432221ff"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "187a8a13"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import time\n"
      ],
      "id": "187a8a13"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "a4dbc391",
        "outputId": "0aef6695-8b9b-459b-9e3d-84c82070bac2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.9.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.6/33.6 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from mediapipe) (0.15.0)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from mediapipe) (1.19.5)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (3.20.3)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.9/dist-packages (from mediapipe) (4.7.0.72)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (22.2.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from mediapipe) (3.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from absl-py->mediapipe) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (23.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (4.39.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (8.4.0)\n",
            "Installing collected packages: flatbuffers, mediapipe\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.5.0 requires flatbuffers~=1.12.0, but you have flatbuffers 23.3.3 which is incompatible.\n",
            "tensorflow-gpu 2.5.0 requires flatbuffers~=1.12.0, but you have flatbuffers 23.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed flatbuffers-23.3.3 mediapipe-0.9.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe\n",
        "import mediapipe as mp"
      ],
      "id": "a4dbc391"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04999353"
      },
      "outputs": [],
      "source": [
        "mp_holistic=mp.solutions.holistic\n",
        "mp_drawing=mp.solutions.drawing_utils"
      ],
      "id": "04999353"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7011f7ba"
      },
      "outputs": [],
      "source": [
        "def mediapipe_detection(image, model):\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
        "    image.flags.writeable = False                  # Image is no longer writeable\n",
        "    results = model.process(image)                 # Make prediction\n",
        "    image.flags.writeable = True                   # Image is now writeable\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
        "    return image, results"
      ],
      "id": "7011f7ba"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d387de9"
      },
      "outputs": [],
      "source": [
        "def draw_landmarks(image, results):\n",
        "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
        "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
        "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections\n",
        ""
      ],
      "id": "0d387de9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e998e5c9"
      },
      "outputs": [],
      "source": [
        "def draw_styled_landmarks(image, results):\n",
        "\n",
        "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
        "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
        "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
        "                             )\n",
        "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
        "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
        "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
        "                             )\n",
        "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
        "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
        "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
        "                             )"
      ],
      "id": "e998e5c9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "collapsed": true,
        "id": "ba90e755",
        "outputId": "1d7d12fd-8304-412c-84e1-061ffdf77a80"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b4654f197bec>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmp_holistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHolistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_detection_confidence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_tracking_confidence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mholistic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
          ]
        }
      ],
      "source": [
        "cap=cv2.VideoCapture(1)\n",
        "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
        "    while cap.isOpened():\n",
        "\n",
        "\n",
        "       ret,frame=cap.read()\n",
        "       image,results=mediapipe_detection(frame,holistic)\n",
        "       print(results)\n",
        "       draw_landmarks(image,results)\n",
        "       cv2.imshow('Open feed',image)\n",
        "\n",
        "\n",
        "       if cv2.waitKey(10) & 0xFF==ord('q'):\n",
        "            break\n",
        "\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "id": "ba90e755"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "8ca11530",
        "outputId": "7040cc19-900b-4f18-970d-0669e840b7e3"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-72efbc972574>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
          ]
        }
      ],
      "source": [
        "len(results.pose_landmarks.landmark)"
      ],
      "id": "8ca11530"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8cKlie3af76",
        "outputId": "60a731b5-550e-469a-cb47-8e66755cbe39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "s8cKlie3af76"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "4878d6c0",
        "outputId": "4cf183c7-4984-4b99-b8fc-3f531a325ef2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-100f62972f2f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
          ]
        }
      ],
      "source": [
        "results"
      ],
      "id": "4878d6c0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7d43596d"
      },
      "outputs": [],
      "source": [
        "frame"
      ],
      "id": "7d43596d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ff4e601"
      },
      "outputs": [],
      "source": [
        "draw_landmarks(frame, results)"
      ],
      "id": "5ff4e601"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "c23ee150"
      },
      "outputs": [],
      "source": [
        "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))"
      ],
      "id": "c23ee150"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96507c92"
      },
      "outputs": [],
      "source": [
        "results.pose_landmarks.landmark[0].visibility"
      ],
      "id": "96507c92"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b64a761d"
      },
      "outputs": [],
      "source": [
        "pose = []\n",
        "for res in results.pose_landmarks.landmark:\n",
        "    test = np.array([res.x, res.y, res.z, res.visibility])\n",
        "    pose.append(test)"
      ],
      "id": "b64a761d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "396e13bd"
      },
      "outputs": [],
      "source": [
        "pose"
      ],
      "id": "396e13bd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e2debfb"
      },
      "outputs": [],
      "source": [
        "pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
        "\n"
      ],
      "id": "4e2debfb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ee032b0"
      },
      "outputs": [],
      "source": [
        "lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)"
      ],
      "id": "3ee032b0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0a40ee7"
      },
      "outputs": [],
      "source": [
        "rh=np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)"
      ],
      "id": "b0a40ee7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "e6c0e6e6"
      },
      "outputs": [],
      "source": [
        "pose"
      ],
      "id": "e6c0e6e6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "629891c3",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "lh.shape"
      ],
      "id": "629891c3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b49d31d8"
      },
      "outputs": [],
      "source": [
        "np.zeros(21*3).shape"
      ],
      "id": "b49d31d8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "b05002b9"
      },
      "outputs": [],
      "source": [
        "lh"
      ],
      "id": "b05002b9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3664e2c9"
      },
      "outputs": [],
      "source": [
        "rh"
      ],
      "id": "3664e2c9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0e7ecac"
      },
      "outputs": [],
      "source": [
        "def extract_keypoints(results):\n",
        "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
        "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
        "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
        "    return np.concatenate([pose, lh, rh])"
      ],
      "id": "e0e7ecac"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d930205b"
      },
      "outputs": [],
      "source": [
        "result_test=extract_keypoints(results)[:10]"
      ],
      "id": "d930205b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "66b59977"
      },
      "outputs": [],
      "source": [
        "result_test"
      ],
      "id": "66b59977"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1dc2ba2"
      },
      "outputs": [],
      "source": [
        "np.save('0', result_test)"
      ],
      "id": "e1dc2ba2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "602f9738"
      },
      "outputs": [],
      "source": [
        "np.load('0.npy')"
      ],
      "id": "602f9738"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e5b54d2"
      },
      "outputs": [],
      "source": [
        "\n",
        "DATA_PATH = os.path.join('DATASET')\n",
        "actions = np.array(['0','1','2','3','4','5','6','7','8','9','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z'])\n",
        "no_sequences = 30\n",
        "sequence_length = 30"
      ],
      "id": "5e5b54d2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67f38e9f"
      },
      "outputs": [],
      "source": [
        "for action in actions:\n",
        "    for sequence in range(no_sequences):\n",
        "        try:\n",
        "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
        "        except:\n",
        "            pass"
      ],
      "id": "67f38e9f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "c1f092bc",
        "outputId": "e6d7174e-9e94-459a-b5a5-1ba690e16936"
      },
      "outputs": [
        {
          "ename": "error",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-4c5a29785175>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0;31m# Make detections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmediapipe_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mholistic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-ccc66144601c>\u001b[0m in \u001b[0;36mmediapipe_detection\u001b[0;34m(image, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmediapipe_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# COLOR CONVERSION BGR 2 RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m                  \u001b[0;31m# Image is no longer writeable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m                 \u001b[0;31m# Make prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m                   \u001b[0;31m# Image is now writeable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ],
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "# Set mediapipe model\n",
        "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
        "\n",
        "    # NEW LOOP\n",
        "    # Loop through actions\n",
        "    for action in actions:\n",
        "        # Loop through sequences aka videos\n",
        "        for sequence in range(no_sequences):\n",
        "            # Loop through video length aka sequence length\n",
        "            for frame_num in range(sequence_length):\n",
        "\n",
        "                # Read feed\n",
        "                ret, frame = cap.read()\n",
        "\n",
        "                # Make detections\n",
        "                image, results = mediapipe_detection(frame, holistic)\n",
        "                print(results)\n",
        "\n",
        "                # Draw landmarks\n",
        "                draw_styled_landmarks(image, results)\n",
        "\n",
        "                # NEW Apply wait logic\n",
        "                if frame_num == 0:\n",
        "                    cv2.putText(image, 'STARTING COLLECTION', (120,200),\n",
        "                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
        "                    cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12),\n",
        "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
        "                    # Show to screen\n",
        "                    cv2.imshow('OpenCV Feed', image)\n",
        "                    cv2.waitKey(2000)\n",
        "                else:\n",
        "                    cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12),\n",
        "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
        "                    # Show to screen\n",
        "                    cv2.imshow('OpenCV Feed', image)\n",
        "                # NEW Export keypoints\n",
        "                keypoints = extract_keypoints(results)\n",
        "                npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n",
        "                np.save(npy_path, keypoints)\n",
        "\n",
        "                # Break gracefully\n",
        "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "                    break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "id": "c1f092bc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81493b42"
      },
      "outputs": [],
      "source": [
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "id": "81493b42"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe1498c4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "id": "fe1498c4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b642b49f"
      },
      "outputs": [],
      "source": [
        "label_map = {label:num for num, label in enumerate(actions)}"
      ],
      "id": "b642b49f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27b0cc99"
      },
      "outputs": [],
      "source": [
        "label_map"
      ],
      "id": "27b0cc99"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f12f5c9"
      },
      "outputs": [],
      "source": [
        "sequences, labels = [], []\n",
        "\n",
        "for action in actions:\n",
        "    for sequence in np.array(os.listdir(os.path.join(DATA_PATH, action))).astype(int):\n",
        "        window = []\n",
        "        for frame_num in range(sequence_length):\n",
        "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
        "            window.append(res)\n",
        "        sequences.append(window)\n",
        "        labels.append(label_map[action])"
      ],
      "id": "0f12f5c9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cba593ca"
      },
      "outputs": [],
      "source": [
        "np.array(sequences).shape"
      ],
      "id": "cba593ca"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abcfcdb0"
      },
      "outputs": [],
      "source": [
        "np.array(labels).shape"
      ],
      "id": "abcfcdb0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5f4f8db"
      },
      "outputs": [],
      "source": [
        "X = np.array(sequences)"
      ],
      "id": "f5f4f8db"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32456e1b"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ],
      "id": "32456e1b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8164a296"
      },
      "outputs": [],
      "source": [
        "y = to_categorical(labels).astype(int)"
      ],
      "id": "8164a296"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4318dbf3"
      },
      "outputs": [],
      "source": [
        "y.shape"
      ],
      "id": "4318dbf3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3427fdf"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"
      ],
      "id": "c3427fdf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c790db3"
      },
      "outputs": [],
      "source": [
        "y_test.shape"
      ],
      "id": "3c790db3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb50cee3"
      },
      "outputs": [],
      "source": [
        "X_test.shape"
      ],
      "id": "fb50cee3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7267dfb"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.callbacks import TensorBoard"
      ],
      "id": "b7267dfb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42d7aaae"
      },
      "outputs": [],
      "source": [
        "log_dir = os.path.join('Logs')\n",
        "tb_callback = TensorBoard(log_dir=log_dir)"
      ],
      "id": "42d7aaae"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edf53595"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ],
      "id": "edf53595"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "457c4f2f"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,258)))\n",
        "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
        "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(actions.shape[0], activation='softmax'))"
      ],
      "id": "457c4f2f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "864d69bb"
      },
      "outputs": [],
      "source": [
        "actions.shape[0]"
      ],
      "id": "864d69bb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f9b3960"
      },
      "outputs": [],
      "source": [
        "res=[.7,0.2,3.5]"
      ],
      "id": "0f9b3960"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04a39afe"
      },
      "outputs": [],
      "source": [
        "res"
      ],
      "id": "04a39afe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ff53cb1"
      },
      "outputs": [],
      "source": [
        "actions[np.argmax(res)]"
      ],
      "id": "6ff53cb1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2911289"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
      ],
      "id": "c2911289"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00ecb2f3"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, y_train, epochs=2000, callbacks=[tb_callback])\n"
      ],
      "id": "00ecb2f3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9417646a"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ],
      "id": "9417646a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "359c4bbb"
      },
      "outputs": [],
      "source": [
        "res = model.predict(X_test)"
      ],
      "id": "359c4bbb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "c5a1458f"
      },
      "outputs": [],
      "source": [
        "res"
      ],
      "id": "c5a1458f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bae7cf4"
      },
      "outputs": [],
      "source": [
        "model.save('DATASET.h5')\n"
      ],
      "id": "2bae7cf4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c826cef4"
      },
      "outputs": [],
      "source": [
        "del model"
      ],
      "id": "c826cef4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01dcec34"
      },
      "outputs": [],
      "source": [
        "model.load_weights('Dataset.h5')"
      ],
      "id": "01dcec34"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b79ca99"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
      ],
      "id": "9b79ca99"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "b912620d",
        "outputId": "629fd93c-e6c4-499c-bb3e-12a44dc2c364"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-412a1357352b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "yhat = model.predict(X_test)"
      ],
      "id": "b912620d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "a8235bfc",
        "outputId": "ab3b7b6f-f5f7-4088-d2fe-bace92ed37f9"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-b600e817e379>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mytrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
          ]
        }
      ],
      "source": [
        "ytrue = np.argmax(y_test, axis=1).tolist()\n",
        "yhat = np.argmax(yhat, axis=1).tolist()"
      ],
      "id": "a8235bfc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "collapsed": true,
        "id": "4f9bb711",
        "outputId": "333e15ff-6051-4970-db0e-4d12182b773d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f0221ea7f982>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmultilabel_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'multilabel_confusion_matrix' is not defined"
          ]
        }
      ],
      "source": [
        "multilabel_confusion_matrix(ytrue, yhat)"
      ],
      "id": "4f9bb711"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df43a855"
      },
      "outputs": [],
      "source": [
        "sequence = []\n",
        "sentence = []\n",
        "threshold = 0.8\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "# Set mediapipe model\n",
        "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
        "    while cap.isOpened():\n",
        "\n",
        "        # Read feed\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        # Make detections\n",
        "        image, results = mediapipe_detection(frame, holistic)\n",
        "        print(results)\n",
        "\n",
        "        # Draw landmarks\n",
        "        draw_styled_landmarks(image, results)\n",
        "\n",
        "        # 2. Prediction logic\n",
        "        keypoints = extract_keypoints(results)\n",
        "        sequence.insert(0,keypoints)\n",
        "        sequence = sequence[:30]\n",
        "\n",
        "        if len(sequence) == 30:\n",
        "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
        "            print(actions[np.argmax(res)])\n",
        "\n",
        "\n",
        "\n",
        "        # Show to screen\n",
        "        cv2.imshow('OpenCV Feed', image)\n",
        "\n",
        "        # Break gracefully\n",
        "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "            break\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "id": "df43a855"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b66980b7"
      },
      "outputs": [],
      "source": [],
      "id": "b66980b7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87f5cc36"
      },
      "outputs": [],
      "source": [],
      "id": "87f5cc36"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}